#summary Plans and progress on developing a subject language classifier

= Introduction =

The basic idea of the subject language classifier is described in the page on [Enrichment] strategy. This page tracks plans and design options and progress toward completing the classifier.

= Training data =

The classifier looks for words and phrases that are language names or other names that are associated with languages (like countries, places, subgroups) and then performs logic over the name strings that are found in order to propose likely subject languages. The classifier is thus trained with facts that are triples consisting of a name string, the kind of name it is, and the code for the language it is associated with. The format for the data used to train the classifier is described elsewhere in   [iso639_trainerDatafileFormat].

In order to support long-term maintenance of this knowledge base, the facts derived from different sources of information are kept in separate files so that they can be managed independently.  When a new version of an information source comes out, the data file for it can be completely regenerated and the all the data reloaded into the classifier. Data files from the following sources are planned:

  * Ethnologue for living language names, alternate names, dialect names, region information, countries, classification
  * Linguist List (http://linguistlist.org/forms/langs/GetListOfAncientLgs.html) for ancient language names, region information, classification
  * ISO 639-3 Names table (http://www.sil.org/iso639-3/download.asp) to get some additional names not in above two (including some French names and constructed language names)
  * LCSH language names (compiled by our project)
  * ISO 3166 codes and country names (!CountryCodes table from http://www.ethnologue.com/codes/) 
  * Scrape historical country names from http://www.nationsonline.org/oneworld/hist_country_names.htm
  * Following http://dbpedia.org/ontology/Country to all of the pages for individual countries we can find the country name in multiple languages as the value of the rdfs:label property
  * The Getty Thesaurus of Geographical Names (http://www.getty.edu/research/tools/vocabulary/tgn/index.html) has multiple current and historical names for countries, but it is not clear that we can automate anything here. This may need to be perused manually at the end to find significant names that are missing.
  * A running list of facts we add as we note striking omissions from the above sources

The files will unavoidably contain duplicate facts. Thus the data loader must note and ignore duplicates.

= Test data =

Two test data sets have been constructed:

  * `olac_display_subset.xml` is the subset from the 50,000+ records currently in the OLAC database that contain at least one subject language code.  It contains 34,319 records.  The records are in `olac_display` format so that they also have a `<dc:subject>` element giving the primary language name associated with the assigned language code. With these in place, the classifier should attain 100% recall. These data will be used for initial testing to ensure that we achieve 100% recall. Further tests will be run without those elements to get a more realistic test of behavior on data such as we might find it in OAI repositories.
  * `marc-to-olac.xml` is a set of 8,891 records generated by the MARC-to-OLAC crosswalk which have yet to be published on the OLAC site. They come from three different source collections and each record similarly has at least one subject language code assigned. In these records there is typically a `<dc:subject>` element with the language name, but in this case was not generated from the code, but was used as unambiguous evidence for assigning the code in the crosswalk.

= Toward maximal recall =

The first problem to be solved by the classifier is to recognize names of languages in metadata. For this it will use information from the first four sets of training data listed above. The other information (like names of associated countries, regions, subgroups) will be used only to increase precision by narrowing the set of languages associated with the discovered names.

Thus the first version of the classifier will be a processor that maximizes recall by identifying all known language names in the metadata and returning the set of all associated language codes. It is not the case that every metadata record has the names of its subject languages in the available metadata. Thus the maximal recall will be well under 100%. The development strategy will be to examine the metadata records for which the classifier proposes no language codes to see if they indeed contain language name clues that are not being found.  Remedies will then be designed and tested. It is already known that a simple matching of available name strings will fail to match a language name in the following cases:

  * Case sensitive matching will work with English titles and descriptions, but in other European languages the names of languages may not be capitalized (such as when used adjectivally).
  * The actual name form occurring in a title or description may be an adjective which adds a suffix.
  * The actual name form occurring in a title or description may differ from our name form by the presence or absence of diacritics. This may especially be true when the metadata is in a language other than English.
  * When our name form is multiple words, the actual name form occurring in a title or description may include just a subphrase of the whole or may have the words in a different order (potentially with intervening punctuation such as parenthesis or comma).
  * When our name form is a hyphenated combination of names, the actual name form occurring in a title or description may include just one of the component names.
 

= A boolean classifier =

Once maximal recall is achieved, we will work to bring in the other available information (such as names of countries, regions, subgroups) to work on increasing the precision (without degrading the recall). We will first experiment to discover the logic that works best for a simple boolean classifier that uses only set operations without any weights or thresholds. The basic idea is that when applying the knowledge from the training data to a metadata record, the classifier will construct three sets:

  * Lang = the set of language codes associated with all of the language names discovered in the metadata
  * Country = the set of language codes associated with all of the country names discovered in the metadata
  * Region = the set of language codes associated with all of the other place names discovered in the metadata

In the following schemas for possible classifier logic, `^` represents set intersection and `v` represents set union. The comma-delimited list means, "Moving from left to right, return the first set that is not null."  Based on the assumption that we never want to return a code that is not in Lang, the following 10 schemas are possible with the three sets above:

  # Lang
  # Lang `^` Country, Lang
  # Lang `^` Region, Lang
  # Lang `^` Country, Lang `^` Region, Lang
  # Lang `^` Region, Lang `^` Country, Lang
  # Lang `^` Country `^` Region, Lang `^` Country, Lang
  # Lang `^` Country `^` Region, Lang `^` Region, Lang
  # Lang `^` Country `^` Region, Lang `^` Country, Lang `^` Region, Lang
  # Lang `^` Country `^` Region, Lang `^` Region, Lang `^` Country, Lang
  # Lang `^` (Country `v` Region), Lang

The simplest classifier (1) just returns the set Lang as described in the preceding section. This will have maximum recall, but low precision (especially when a single name, e.g. Quechua, could be associated with dozens of language codes). We can thus make the classifier more precise by using the clues of country names and region names to narrow the choices down to the most likely candidates. In classifier (2) we return the intersection of Lang and Country, unless that is empty, in which case we fall back to Lang. Or we could do the same with Region (3). Classifiers (4) and (5) use all three sets, but never more than two at a time and differ by the preference they give to country names versus region names. (6) through (9) are same as (2) to (5) except they insert intersection of all three sets as the first preference. Finally, (10) gives equal credence to Country and Region and thus takes the union of the two sets as the set for intersecting with Lang.

We will run trials of all 10 classifier models against the test data, calculating recall and precision for each. In this way we will be able to evaluate which logic gives the best results.

Another experiment can take the most promising results with the three sets named above and test various ways of adding a fourth set that is available to us, namely, names of subgroups in the classification of a language.

Everything above has talked about matching names. The classifier must also be able to match the ISO 3166 country codes directly since these may be encountered in Dublin Core metadata.  If the content of `<dc:coverage>` or `<dcterms:spatial>` is exactly two letters, then it should be matched against the ISO 3166 code list to give evidence for a country match.  (We should not try to match ISO 3166 codes in any other context as that will just reduce precision with extraneous matches of two-letter words.)

= A weighted classifier =

The simple Lang classifier (1 above) offers the theoretical upper limit on recall. The refined models above seek to improve precision without degrading recall. If the level of precision achieved with the best boolean classifier is still not high enough, then we can seek further precision by constructing a weighted classifier.

Rather than manipulating sets of language codes that are indicated by the occurrence of name strings in the metadata, a weighted classifier would manipulate vectors of scores associated with language codes. A score of 0 would indicate that there is no evidence for that language, while a non-zero score would indicate evidence for that language. The higher the score, the greater the weight for that conclusion.

The basic idea is that when applying the knowledge from the training data to a metadata record, the classifier will construct three vectors of weights for possible codes:

  * Lang = the vector of weights for language codes following identification of language names in the metadata
  * Country = the vector of weights for language codes following identification of country names (and codes) in the metadata
  * Region = the vector of weights for language codes following identification of region names in the metadata

The classifier then depends on the definition of a "select" function which selects the most likely language codes out of the resulting vector. The following is a basic schema for the classifier logic, where '+' and 'x' represent arithmetic addition and multiplication of the weights of corresponding language codes in the two operand vectors to produce a new result vector, and 'a' and 'b' represent constant multipliers in the range of 0 to 1 which control the relative contribution of country and region clues. Based on the assumption that we never want to return a non-zero for a code that is not supported by the presence of a corresponding language name, the following 4 schemas are possible with the three sets above:

  * select(Lang + a(Lang x Country) + b(Lang x Region))

The use of multiplication serves to cancel out the evidence rendered by a particular country or region name when no language name associated with the code has been identified. The use of plus serves to reinforce the weight for the language when country and region names supporting the same code are discovered.

Weighting could come from any or all of the following sources:

  * Weighting by the type of information. That is, more weight could be initially given a strong language name than a weak language name (see page on [iso639_trainerDatafileFormat training data format]). 
  * Weighting by the length of match.  That is, more weight could be given to a three-word name match than to a two-word match than to a single-word match. Or, weight could be assigned in proportion to the total string length of the matched name.
  * Weighting by the number of occurrences.  That is, every time the same name in encountered again, it could add to the weight for its associated codes.
  * Weighting by the source fields. That is, a language name found in a title or subject could be given more weight than one found in a description (since, for instance, an abstract could make reference to languages that give a point of reference but which the resource is not really about.) Alternatively, the description element could be treated by giving names near the beginning of the description more weight than names that are well into a long description.


= Integration with harvester =

Currently, we anticipate three contexts in which the subject language classifier will be applied:

  # Within the OLAC Aggregator to see if we can identify any subject languages for records that are lacking a coded subject language
  # Within the OAI harvester to see if we can identify records from a general OAI data provider that have a subject language
  # Within the MARC-to-OLAC crosswalk to see if we can identify any subject languages for records that still lack a coded subject language after the crosswalking step

To support these applications, we will need for the classifier to be a Python function that can be called from the harvesters and the crosswalk. For inputs it would have the contents of the relevant metadata fields from the record being classified. For the output it would have the possible language codes with their assigned weight. Alternatively, the weight threshold could be an input and the output just a set of codes that are above the threshold level.
