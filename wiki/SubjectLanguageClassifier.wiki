#summary Plans and progress on developing a subject language classifier

= Introduction =

The basic idea of the subject language classifier is described in the page on [Enrichment] strategy. This page tracks plans and design options and progress toward completing the classifier.

= Training data =

The classifier looks for words and phrases that are language names or other names that are associated with languages (like countries, places, subgroups) and then performs logic over the name strings that are found in order to propose likely subject languages. The classifier is thus trained with facts that are triples consisting of a name string, the kind of name it is, and the code for the language it is associated with. The format for the data used to train the classifier is described elsewhere in   [iso639_trainerDatafileFormat].

In order to support long-term maintenance of this knowledge base, the facts derived from different sources of information are kept in separate files so that they can be managed independently.  When a new version of an information source comes out, the data file for it can be completely regenerated and the all the data reloaded into the classifier. Data files from the following sources are planned:

  * Ethnologue for living language names, alternate names, dialect names, region information, countries, classification
  * Linguist List (http://linguistlist.org/forms/langs/GetListOfAncientLgs.html) for ancient language names, region information, classification
  * ISO 639-3 Names table (http://www.sil.org/iso639-3/download.asp) to get some additional names not in above two (including some French names and constructed language names)
  * LCSH language names (compiled by our project)
  * ISO 3166 codes and country names (!CountryCodes table from http://www.ethnologue.com/codes/) 
  * Scrape historical country names from http://www.nationsonline.org/oneworld/hist_country_names.htm
  * Following http://dbpedia.org/ontology/Country to all of the pages for individual countries we can find the country name in multiple languages as the value of the rdfs:label property
  * The Getty Thesaurus of Geographical Names (http://www.getty.edu/research/tools/vocabulary/tgn/index.html) has multiple current and historical names for countries, but it is not clear that we can automate anything here. This may need to be perused manually at the end to find significant names that are missing.
  * A running list of facts we add as we note striking omissions from the above sources

The files will unavoidably contain duplicate facts. Thus the data loader must note and ignore duplicates.

= Test data =

Two test data sets have been constructed:

  * `olac_display_subset.xml` is the subset from the 50,000+ records currently in the OLAC database that contain at least one subject language code.  It contains 34,319 records.  The records are in `olac_display` format so that they also have a `<dc:subject>` element giving the primary language name associated with the assigned language code. With these in place, the classifier should attain 100% recall. These data will be used for initial testing to ensure that we achieve 100% recall. Further tests will be run without those elements to get a more realistic test of behavior on data such as we might find it in OAI repositories.
  * `marc-to-olac.xml` is a set of 8,891 records generated by the MARC-to-OLAC crosswalk which have yet to be published on the OLAC site. They come from three different source collections and each record similarly has at least one subject language code assigned. In these records there is typically a `<dc:subject>` element with the language name, but in this case was not generated from the code, but was used as unambiguous evidence for assigning the code in the crosswalk.

= A boolean classifier =

First, we will experiment to discover the logic that works best for a simple boolean classifier that uses only set operations without any weights or thresholds. The basic idea is that when applying the knowledge from the training data to a metadata record, the classifier will construct three sets:

  * Lang = the set of language codes associated with all of the language names discovered in the metadata
  * Country = the set of language codes associated with all of the country names discovered in the metadata
  * Region = the set of language codes associated with all of the other place names discovered in the metadata

In the following schemas for possible classifier logic, `^` represents set intersection and `v` represents set union. The comma-delimited list means, "Moving from left to right, return the first set that is not null."  Based on the assumption that we never want to return a code that is not in Lang, the following 10 schemas are possible with the three sets above:

  # Lang
  # Lang `^` Country, Lang
  # Lang `^` Region, Lang
  # Lang `^` Country, Lang `^` Region, Lang
  # Lang `^` Region, Lang `^` Country, Lang
  # Lang `^` Country `^` Region, Lang `^` Country, Lang
  # Lang `^` Country `^` Region, Lang `^` Region, Lang
  # Lang `^` Country `^` Region, Lang `^` Country, Lang `^` Region, Lang
  # Lang `^` Country `^` Region, Lang `^` Region, Lang `^` Country, Lang
  # Lang `^` (Country `v` Region), Lang

The simplest classifier (1) just returns the set Lang. This would have maximum recall, but low precision (especially when a single name, e.g. Quechua, could be associated with dozens of language codes). We can thus make the classifier more precise by using the clues of country names and region names to narrow the choices down to the most likely candidates. In classifier (2) we return the intersection of Lang and Country, unless that is empty, in which case we fall back to Lang. Or we could do the same with Region (3). Classifiers (4) and (5) use all three sets, but never more than two at a time and differ by the preference they give to country names versus region names. (6) through (9) are same as (2) to (5) except they insert intersection of all three sets as the first preference. Finally, (10) gives equal credence to Country and Region and thus takes the union of the two sets as the set for intersecting with Lang.

We will run trials of all 10 classifier models against the test data, calculating recall and precision for each. In this way we will be able to evaluate which logic gives the best results.

Another experiment can take the most promising results with the three sets named above and test various ways of adding a fourth set that is available to us, namely, names of subgroups in the classification of a language.

Everything above has talked about matching names. The classifier must also be able to match the ISO 3166 country codes directly since these may be encountered in Dublin Core metadata.  If the content of `<dc:coverage>` or `<dcterms:spatial>` is exactly two letters, then it should be matched against the ISO 3166 code list to give evidence for a country match.  (We should not try to match ISO 3166 codes in any other context as that will just reduce precision with extraneous matches of two-letter words.)

= A weighted classifier =

Weight the source fields

Weight the length of match

Weight the type of information